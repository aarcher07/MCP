{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'colour'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e873930c7d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcolour\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msklearnPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'colour'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "from scipy.constants import *\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from colour import Color\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains all of the parameters necessary to run the integration of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kcat0 = 3.e2 #Reaction rate for S->I for a single reaction site\n",
    "N0 = 1.5e3 #Number of reaction sites for S->I reaction\n",
    "K0 = 0.5e3 #Half max concentration for S->I reaction\n",
    "kcat1 = 55. #Reaction rate for I->P for a single reaction site\n",
    "N1 = 2.5e3 #Number of reaction sites for I->P reaction\n",
    "K1 = 15.e3 #Half max concentration for I->P reaction\n",
    "perm0c = 1.e-5 #Permeability of S through compartment\n",
    "perm1c = 1.e-5 #Permeability of I through compartment\n",
    "perm2c = 1.e-5 #Permeability of P through compartment\n",
    "perm0b = 1.e-3 #Permeability of S through cell\n",
    "perm1b = 1.e-3 #Permeability of I through cell\n",
    "perm2b = 1.e-3 #Permeability of P through cell\n",
    "Rc = 1.e-5 #Radius of compartment (cm)\n",
    "Rb = 5.e-5 #Effective Radius of cell (cm)\n",
    "Diff = 1.e-4 #Diffusion coefficient\n",
    "SInit = 700. #Initial concentration of external substrate\n",
    "\n",
    "V0 = kcat0*N0*1.e9/(Avogadro*(4.*pi/3.)*Rc**3) #Max reaction rate S->I (units scaling taken into account)\n",
    "V1 = kcat1*N1*1.e9/(Avogadro*(4.*pi/3.)*Rc**3) #Max reaction rate I->P (units scaling taken into account)\n",
    "\n",
    "ngrid = 25 #number of desired grid points for the integration inside the cell (but outside the MCP)\n",
    "Vratio = 10 #This is the multiplier between the external and cell volumes in the solution (Vratio = Vexternal/Vcell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a function for the derivative of the states. The output of this derivative is a vector of the same length as the state vectors.\n",
    "\n",
    "The derivative calculated here is for the unitless/rescaled version of the equations. This is due to the fact that all the units are significantly different orders of magnitude causing many issues with stability of the equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDeriv(x,t): #spatial derivative\n",
    "    \n",
    "    ### why this scaling ####\n",
    "    \n",
    "    Mb = (Rb/Rc)**3/3.\n",
    "    Vext = 4*pi*Mb*Vratio\n",
    "    Mc = 1./3.\n",
    "    DeltaM = np.divide((Mb-Mc),(ngrid))\n",
    "    \n",
    "    ### why this scaling ####\n",
    "    \n",
    "    M = np.linspace(Mc-DeltaM/2.,Mb+DeltaM/2.,ngrid+2) # is this correct?\n",
    "    \n",
    "    \n",
    "    D = Diff/(Rc**2)\n",
    "    k0c = perm0c/Rc #scaled permeability of S through compartment\n",
    "    k1c = perm1c/Rc #scaled permeability of I through compartment\n",
    "    k2c = perm2c/Rc #scaled permeability of P through compartment\n",
    "    k0b = perm0b/Rc #scaled permeability of S through cell\n",
    "    k1b = perm1b/Rc #scaled permeability of S through cell\n",
    "    k2b = perm2b/Rc #scaled permeability of S through cell\n",
    "    rc = 1.\n",
    "    rb = Rb/Rc\n",
    "    M[0] = Mc # why?\n",
    "    M[-1] = Mb #why?\n",
    "    v0 = V0/K0\n",
    "    v1 = V1/K1\n",
    "    kappa01 = K0/K1\n",
    "    assert len(x) == 3*(2+(ngrid))\n",
    "    d = np.zeros((len(x)))\n",
    "    d[0] = -(x[0]*v0)/(1. + x[0]) + 3.*k0c*(x[3] - x[0])/rc     #microcompartment equation for S\n",
    "    d[1] = (x[0]*v0*kappa01)/(1. + x[0]) -(x[1]*v1)/(1. + x[1]) + 3.*k1c*(x[4] - x[1])/rc #microcompartment equation for I\n",
    "    d[2] = (x[1]*v1)/(2.*(1. + x[1])) + 3.*k2c*(x[5] - x[2])/rc #microcompartment equation for P\n",
    "    \n",
    "    d[-3] = 12.*pi*Mb*k0b*(x[-6] - x[-3])/(rb*Vext) #external equation for S \n",
    "    d[-2] = 12.*pi*Mb*k1b*(x[-5] - x[-2])/(rb*Vext) #external equation for I\n",
    "    d[-1] = 12.*pi*Mb*k2b*(x[-4] - x[-1])/(rb*Vext) #external equation for P\n",
    "    \n",
    "    for k in range(2,(ngrid+1)):\n",
    "        i = 3*k\n",
    "        d[i] =   ((3**(4./3.))*D/(DeltaM)**2)*((M[k])**(4./3.)*(x[i+3]-x[i])- (M[k-1])**(4./3.)*(x[i]-x[i-3]))\n",
    "        d[i+1] = ((3**(4./3.))*D/(DeltaM)**2)*((M[k])**(4./3.)*(x[i+4]-x[i+1])- (M[k-1])**(4./3.)*(x[i+1]-x[i-2]))\n",
    "        d[i+2] = ((3**(4./3.))*D/(DeltaM)**2)*((M[k])**(4./3.)*(x[i+5]-x[i+2])- (M[k-1])**(4./3.)*(x[i+2]-x[i-1])) \n",
    "    \n",
    "    d[3] = ((3**(4./3.))*D/(DeltaM)**2)*((M[1])**(4./3.)*(x[6]-x[3])) - 3.*k0c*(x[3] - x[0])*Mc/(rc*DeltaM) # BC for for S with microcomparment and cell\n",
    "    d[4] = ((3**(4./3.))*D/(DeltaM)**2)*((M[1])**(4./3.)*(x[7]-x[4])) - 3.*k1c*(x[4] - x[1])*Mc/(rc*DeltaM) # BC for for I with microcomparment and cell\n",
    "    d[5] = ((3**(4./3.))*D/(DeltaM)**2)*((M[1])**(4./3.)*(x[8]-x[5])) - 3.*k2c*(x[5] - x[2])*Mc/(rc*DeltaM) # BC for for P with microcomparment and cell\n",
    "    \n",
    "    d[-6] = -3.*k0b*(x[-6] - x[-3])*Mb/(rb*DeltaM) - ((3**(4./3.))*D/(DeltaM)**2)*((M[ngrid])**(4./3.)*(x[-6]-x[-9])) # BC for for S with external environment and cell\n",
    "    d[-5] = -3.*k1b*(x[-5] - x[-2])*Mb/(rb*DeltaM) - ((3**(4./3.))*D/(DeltaM)**2)*((M[ngrid])**(4./3.)*(x[-5]-x[-8])) # BC for for I with external environment and cell\n",
    "    d[-4] = -3.*k2b*(x[-4] - x[-1])*Mb/(rb*DeltaM) - ((3**(4./3.))*D/(DeltaM)**2)*((M[ngrid])**(4./3.)*(x[-4]-x[-7])) # BC for for P with external environment and cell\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = np.zeros((ngrid*3+6))\n",
    "y0[-3] = SInit/K0 #y0[-3] gives the initial state of the external substrate. The /K0 turns the value into a dimensionless quantity\n",
    "timeorig = np.linspace(0,50000,1000)\n",
    "Kscale = np.array([K0,K1,K1]) #Creates a vector of metabolite scaling values\n",
    "Equilibrium = Vratio*SInit/(Vratio+1.) #This takes into account that there is no substrate inside the cell at the start and finds the equilibrium concentration when it has diffused into the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells are used only if you have not generated/saved data already\n",
    "\n",
    "The following cell calculates the time series going forward for a grid of permeabilities. Each set of permeabilities uses the same time points and is integrated for the same amount of time.\n",
    "\n",
    "This causes poor resolution for the faster paths. The results of this cell will be used to determine the time necessary to properly resolve each set of parameter values for when the \"progress\" calculation is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================       ]      [=============================================      ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ash4334/.local/lib/python2.7/site-packages/scipy/integrate/odepack.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================================]      [===================================================]"
     ]
    }
   ],
   "source": [
    "sol = np.zeros((51,51,1000,3*(ngrid+2)))\n",
    "values = np.linspace(-6,-3,51)\n",
    "\n",
    "for i in (range(51)):\n",
    "    perm0c = 10**(values[i])\n",
    "    perm1c = perm0c\n",
    "    perm2c = perm0c\n",
    "    for j in (range(51)):\n",
    "        a = sys.stdout\n",
    "        a.write('\\r')\n",
    "        a.write('[%-51s]      [%-51s]' % ('='*(i+1),'='*(j+1)))\n",
    "        a.flush()\n",
    "        perm0b = 10**(values[j]+1)\n",
    "        perm1b = perm0b\n",
    "        perm2b = perm0b\n",
    "        sol[i,j] = odeint(SDeriv, y0, timeorig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('WildType/States-SameTime.npy',sol) #Saving the data from the previous cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell takes the data from the previous integration and determines the time at which each parameter set reaches 95% of the equilibrium value of the final product. This time is then multiplied by 2 and used as the new end point for the time series. This adjustment allows you to adjust the resolution of the time series to the time it takes to reach equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "EquilibriumTime = np.zeros((51,51))\n",
    "for i in range(51):\n",
    "    for j in range(51):\n",
    "        complete = np.where(sol[i,j,:,-1]*Kscale[-1]>=0.95*SInit*0.5*(10./11.))\n",
    "        if len(complete[0])>0:\n",
    "            EquilibriumTime[i,j] = timeorig[np.min(complete[0])]*2\n",
    "        else:\n",
    "            EquilibriumTime[i,j] = timeorig[-1]*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the end point defined in the previous cell, the next one solves for the full time series up to that time for each parameter set. This set of data is then going to be converted into (progress, concentration) series - instead of (time, concentration). Because each path stops around equilibrium and is well resolved throughout the progress of the path we are able to get enough resolution in progress space for all parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================================]      [===================================================]"
     ]
    }
   ],
   "source": [
    "rescaledsol = np.zeros((51,51,1000,3*(ngrid+2)))\n",
    "Times = np.zeros((51,51,1000))\n",
    "\n",
    "for i in (range(51)):\n",
    "    perm0c = 10**(values[i])\n",
    "    perm1c = perm0c\n",
    "    perm2c = perm0c\n",
    "    for j in (range(51)):\n",
    "        Time = np.linspace(0,EquilibriumTime[i,j],1000)\n",
    "        Times[i,j] = Time\n",
    "        a = sys.stdout\n",
    "        a.write('\\r')\n",
    "        a.write('[%-51s]      [%-51s]' % ('='*(i+1),'='*(j+1)))\n",
    "        a.flush()\n",
    "        perm0b = 10**(values[j]+1)\n",
    "        perm1b = perm0b\n",
    "        perm2b = perm0b\n",
    "        rescaledsol[i,j] = odeint(SDeriv, y0, Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('WildType/States-ScaledTime.npy',rescaledsol)\n",
    "np.save('WildType/ScaledTimes.npy',Times)\n",
    "#This cell saves both the Time series and the times at which the data is collected for all parameter sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is used if you already have saved time series\n",
    "\n",
    "If you do not want to take the time to integrate the dynamics above - or you have already done this and saved the data, you can load the data series in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledsol = np.load('WildType/States-ScaledTime.npy')\n",
    "Times = np.load('WildType/ScaledTimes.npy')\n",
    "sol = np.load('WildType/States-SameTime.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on all cells are used regardless of if you have previously generated data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a grid of parameter values - This will be used later to define the grid when plotting the model surface \n",
    "\n",
    "kc = np.zeros((51,51))\n",
    "kb = np.zeros((51,51))\n",
    "\n",
    "for i in (range(51)):\n",
    "    for j in (range(51)):\n",
    "        kc[i,j] = 10**(values[i])\n",
    "        kb[i,j] = 10**(values[j]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells are used to define progress and calculate split the data points into progress \"bins\"\n",
    "\n",
    "\\begin{equation}p = \\frac{2 m_\\perp P_{ext} - S_{ext} + S_0}{S_0(1+m_\\perp^2)}\\end{equation}\n",
    "\n",
    "Here $m_\\perp \\equiv \\frac{V_{ratio}}{1+V_{ratio}}$\n",
    "\n",
    "Then $D_{\\perp}$ is defined as the distance from the point of the path in (P,S) space to the line that connects the initial and final points of the path in (P,S) space\n",
    "\n",
    "\\begin{equation}\n",
    "D_\\perp = \\sqrt{4 P_{ext}^2 + (S_{ext} - S_0)^2 - [l(S_{ext},P_{ext},S_0)]^2} \\end{equation}\n",
    "\n",
    "where we define\n",
    "\\begin{equation} l(S_{ext},P_{ext},S_0) = \\frac{2 m_\\perp P_{ext} - S_{ext} +S_0}{\\sqrt{1+m_\\perp^2}}\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(S,P,S0):\n",
    "    mperp = np.divide(np.float(Vratio),np.float(Vratio)+1.)\n",
    "    return np.divide(2*mperp*P - S + S0,S0*(1+mperp**2))\n",
    "\n",
    "def l(S,P,S0):\n",
    "    mperp = np.divide(np.float(Vratio),np.float(Vratio)+1.)\n",
    "    return np.divide(2*mperp*P - S + S0,np.sqrt(1+mperp**2))\n",
    "    \n",
    "\n",
    "def Dperp(S,P,S0):\n",
    "    mperp = np.divide(np.float(Vratio),np.float(Vratio)+1.)\n",
    "    return np.sqrt(4*P**2 + (S-S0)**2 - l(S,P,S0)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell calculates the progress and $D_\\perp$ values for each time point for each parameter set using the scaled time set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "progressvalues = np.zeros((51,51,1000))\n",
    "Disp = np.zeros((51,51,1000))\n",
    "\n",
    "for i in range(51):\n",
    "    for j in range(51):\n",
    "        progressvalues[i,j] = p(rescaledsol[i,j,:,-3]*Kscale[0],rescaledsol[i,j,:,-1]*Kscale[2],SInit)\n",
    "        Disp[i,j] = Dperp(rescaledsol[i,j,:,-3]*Kscale[0],rescaledsol[i,j,:,-1]*Kscale[2],SInit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates a list called \"ByProgress\" the i'th element of this list is the set of all points in $(Intermediate,D_\\perp)$ space that exist between the i'th and (i+1)'st percentage values of progress.\n",
    "\n",
    "Because some paths are more resolved or take longer in certain regions than others, you get that there are often multiple time points from a single path that land in the same progress set. This should be fine because they are close to one another and should not add too much excess variation when doing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "ByProgress = []\n",
    "for i in np.arange(0,1,0.01):\n",
    "    placeholder = rescaledsol[:,:,:,-3:][np.where(np.logical_and(progressvalues>=i,progressvalues<i+0.01))]*Kscale\n",
    "    placeholderInt = placeholder[:,1]\n",
    "    placeholderD = Dperp(placeholder[:,0],placeholder[:,2],SInit)\n",
    "    placeholder2 = np.array([placeholderInt,placeholderD])\n",
    "    ByProgress.append(placeholder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we take each element in the \"ByProgress\" list - remember, these are a set of 2-D points - and calculate PCA on them. This gives us the variation in the $D_\\perp$ and Intermediate metabolite at each progress value.\n",
    "\n",
    "The eigenvectors, eigenvalues, and eigenvalue ratios are all saved for each progress value.\n",
    "\n",
    "We then plot the eigenvalues over progress to show how the variation changes as the dynamics progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "progressPCA = np.array([0])\n",
    "pca = sklearnPCA()\n",
    "PCA_Vectors = []\n",
    "PCA_Values = []\n",
    "PCA_Ratios = []\n",
    "for i in range(1,100):\n",
    "    if len(ByProgress[i][0]>0):\n",
    "        progressPCA = np.vstack([progressPCA,i])\n",
    "        X = ByProgress[i].T\n",
    "        pca.fit(X)\n",
    "        PCA_Vectors.append(pca.components_)\n",
    "        PCA_Values.append(pca.explained_variance_)\n",
    "        PCA_Ratios.append(pca.explained_variance_ratio_)\n",
    "        \n",
    "progressPCA = np.reshape(progressPCA[1:],-1)\n",
    "PCA_Vectors = np.asarray(PCA_Vectors)\n",
    "PCA_Values = np.asarray(PCA_Values)\n",
    "PCA_Ratios = np.asarray(PCA_Ratios)\n",
    "\n",
    "plt.plot(progressPCA,PCA_Values[:,0])\n",
    "plt.plot(progressPCA,PCA_Values[:,1])\n",
    "plt.xlabel('progress')\n",
    "plt.ylabel('Eigenvalues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of all dimensions with  progress as independent variable. This is to help visualize the space in progress\n",
    "#instead of time.\n",
    "\n",
    "colors = ['#332288', '#88CCEE', '#117733','#DDCC77', '#CC6677','#AA4499']\n",
    "\n",
    "plt.suptitle('States vs Progress',fontsize = 20)\n",
    "\n",
    "plt.subplot(221)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(progressvalues[i,j]*100,rescaledsol[i,j,:,-2]*Kscale[1],colors[0])\n",
    "plt.axvline(x=progressPCA[np.argmax(PCA_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Intermediate Metabolite\\nConcentration',fontsize = 15)\n",
    "        \n",
    "plt.subplot(222)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(progressvalues[i,j]*100,Disp[i,j],colors[1])\n",
    "plt.axvline(x=progressPCA[np.argmax(PCA_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Distance from\\nProgress Metric',fontsize = 15)\n",
    "        \n",
    "plt.subplot(223)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(progressvalues[i,j]*100,rescaledsol[i,j,:,-3]*Kscale[0],colors[2])\n",
    "plt.axvline(x=progressPCA[np.argmax(PCA_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Substrate Metabolite\\nConcentration',fontsize = 15)\n",
    "plt.xlabel('Progress',fontsize = 15)\n",
    "        \n",
    "plt.subplot(224)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(progressvalues[i,j]*100,rescaledsol[i,j,:,-1]*Kscale[2],colors[4])\n",
    "plt.axvline(x=progressPCA[np.argmax(PCA_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Product Metabolite\\nConcentration',fontsize = 15)\n",
    "plt.xlabel('Progress',fontsize = 15)\n",
    "        \n",
    "plt.tight_layout()      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take the data that was originally collected at all the same time points (This is the first set of data that was made) and look at the variation of the three metabolite concentrations over time.\n",
    "\n",
    "Because the product is split between 2 different products and it appears (if you didn't know that there were 2 products) that the product somehow managed to make half the mass disappear, we run PCA in $(S,I,2P)$ space. This also allows us to  make sure that the fact that the scale of the product being half the scale of the other two metabolites doesn't affect the results\n",
    "\n",
    "We again plot the eigenvalues over time to show that there is a peak in eigenvalue and variability\n",
    "\n",
    "*Note*: In this case we have a 3d space while in the progress case we have a 2d space. This is because when we choose to have progress as our independent variable, the S and P variables are now coupled and not independent - since their relationship defines progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_T_Vectors = []\n",
    "PCA_T_Values = []\n",
    "PCA_T_Ratios = []\n",
    "\n",
    "for t in range(0,len(timeorig)):\n",
    "    x1 = np.reshape(sol[:,:,t,-3]*Kscale[0],(-1))\n",
    "    x2 = np.reshape(sol[:,:,t,-2]*Kscale[1],(-1))\n",
    "    x3 = 2*np.reshape(sol[:,:,t,-1]*Kscale[1],(-1))\n",
    "    X = np.array([x1,x2,x3]).T\n",
    "    pca.fit(X)\n",
    "    PCA_T_Vectors.append(pca.components_)\n",
    "    PCA_T_Values.append(pca.explained_variance_)\n",
    "    PCA_T_Ratios.append(pca.explained_variance_ratio_)\n",
    "\n",
    "PCA_Time = timeorig\n",
    "PCA_T_Vectors = np.asarray(PCA_T_Vectors)    \n",
    "PCA_T_Values = np.asarray(PCA_T_Values)    \n",
    "PCA_T_Ratios = np.asarray(PCA_T_Ratios)\n",
    "\n",
    "plt.plot(PCA_Time,PCA_T_Values[:,0])\n",
    "plt.plot(PCA_Time,PCA_T_Values[:,1])\n",
    "plt.plot(PCA_Time,PCA_T_Values[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we plot several paths to show how the parameter values affect the time series. The black line marks the time at\n",
    "#which we have the largest eigenvalue\n",
    "\n",
    "colors = ['#332288', '#88CCEE', '#117733','#DDCC77', '#CC6677','#AA4499']\n",
    "\n",
    "plt.suptitle('States vs Time',fontsize = 20)\n",
    "\n",
    "plt.subplot(221)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(timeorig,sol[i,j,:,-2]*Kscale[1],colors[0])\n",
    "plt.axvline(x=PCA_Time[np.argmax(PCA_T_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Intermediate Metabolite\\nConcentration',fontsize = 15)\n",
    "        \n",
    "plt.subplot(222)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(timeorig,sol[i,j,:,-3]*Kscale[0],colors[2])\n",
    "plt.axvline(x=PCA_Time[np.argmax(PCA_T_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Substrate Metabolite\\nConcentration',fontsize = 15)\n",
    "plt.xlabel('Time',fontsize = 15)\n",
    "        \n",
    "plt.subplot(223)\n",
    "for i in range(0,51,5):\n",
    "    for j in range(0,51,5):\n",
    "        plt.plot(timeorig,sol[i,j,:,-1]*Kscale[2],colors[4])\n",
    "plt.axvline(x=PCA_Time[np.argmax(PCA_T_Values[:,0])],color = 'k')\n",
    "plt.ylabel('Product Metabolite\\nConcentration',fontsize = 15)\n",
    "plt.xlabel('Time',fontsize = 15)\n",
    "        \n",
    "plt.tight_layout()      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished calculating PCA for both time and progress space, we analyze these results.\n",
    "\n",
    "First Progress:\n",
    "\n",
    "We want to find the point at which the progress of each path corresponds to the highest eigenvalue. This particular point in the path will be used as an observation. We will choose 1 path to be the \"truth\" and will calculate the error surface between this \"true\" path and all the others using just the most first eigenvector of the most variable progress point for each eigenvalue.\n",
    "\n",
    "Since the progress is not calculated at exactly the same points, we need to determine what the progress is at the points closest to the most variable progress point. And look up the value of the states at those points.\n",
    "\n",
    "We also want to look at just the first eigenvector, in progress space because if we look at the eigenvalue decomposition, the first eigenvector contains close to 100% of the variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a path to be our \"True\" Path. This will be an index for the parameters that we want to  be the correct value we will compare to. I've chosen indices that approximately match what we expect the permeabilities to be.\n",
    "\n",
    "This truth value will be the same for all analysis used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_index = (15,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the progress value at which the eigenvalue is largest\n",
    "VarProg = progressPCA[np.argmax(PCA_Values[:,0])]*0.01 #this is as a fraction\n",
    "VarProgPercent = progressPCA[np.argmax(PCA_Values[:,0])] #This is a percentage and an index to be plugged into the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the point in each time series that ends up with the closest progress to the one picked out by PCA\n",
    "\n",
    "closestProg = np.zeros((51,51))\n",
    "locProg = np.zeros((51,51))\n",
    "\n",
    "for i in range(51):\n",
    "    for j in range(51):\n",
    "        loc = np.argmin((progressvalues[i,j]-VarProg)**2)\n",
    "        closestProg[i,j] = (progressvalues[i,j,loc])\n",
    "        locProg[i,j] = np.int(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the vectors of (Intermediate,Dperp) coordinates for the points corresponding to the highest variability in progress\n",
    "\n",
    "Data_Var_Prog = np.zeros((51,51,2))\n",
    "\n",
    "for i in range(51):\n",
    "    for j in range(51):\n",
    "        time_of_prog = int(locProg[i,j])\n",
    "        Data_Var_Prog[i,j] = np.array([rescaledsol[i,j,time_of_prog,-2]*Kscale[1],Disp[i,j,time_of_prog]])\n",
    "Data_Var_Prog_reshape = np.reshape(Data_Var_Prog,(51*51,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the the length of both eigenvectors using the (Int,Dperp) data points and the eigenvectors found in PCA\n",
    "\n",
    "PCA_Var_Vec_reshape = np.array([np.dot(Data_Var_Prog_reshape,PCA_Vectors[VarProgPercent,0]),np.dot(Data_Var_Prog_reshape,PCA_Vectors[VarProgPercent,1])])\n",
    "PCA_Var_Vec = np.array([np.dot(Data_Var_Prog,PCA_Vectors[VarProgPercent,0]),np.dot(Data_Var_Prog,PCA_Vectors[VarProgPercent,1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate error between First eigenvector length for progress PCA as compared to the \"true\" path. This is a percent\n",
    "#error and is calculated by a difference divided by the length of the true path eigenvector\n",
    "PCA_Error = np.divide(np.absolute(PCA_Var_Vec[(0,) + truth_index] - PCA_Var_Vec[0]),np.absolute(PCA_Var_Vec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error calculated above as a heat map. The white star corresponds to the \"true\" path. The white contour\n",
    "#corresponds to 1% error\n",
    "\n",
    "cont = plt.pcolormesh(kc,kb,PCA_Error,norm = matplotlib.colors.LogNorm(),shading = 'gouraud',cmap = 'magma')\n",
    "plt.scatter(kc[truth_index],kb[truth_index],marker = '*',color = 'white')\n",
    "plt.contour(kc,kb,PCA_Error,levels = [0.1])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.colorbar(cont,label = 'Percent Error Compared to \"Truth\"')\n",
    "plt.ylabel('Cell Permeability')\n",
    "plt.xlabel('MicroCompartment Permeability')\n",
    "plt.title('Error Plot Using Most Variable Progress Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same error calculation  using the  most variable time point instead of progress. Again, only using the first eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the time point at which the eigenvalue is largest when doing PCA over time\n",
    "#Collect a set of data points in (S,I,2P) for that specific time value\n",
    "\n",
    "#NOTE: It is important that you save 2*P as your last dimension in the data points because that is what PCA was done using\n",
    "#And your eigenvector has 2*P as one of the dimensions, NOT just P\n",
    "\n",
    "Data_Var_Time = np.zeros((51,51,3))\n",
    "\n",
    "PCATimeIndex = np.argmax(PCA_T_Values[:,0])\n",
    "\n",
    "for i in range(51):\n",
    "    for j in range(51):\n",
    "        Data_Var_Time[i,j] = np.array([sol[i,j,PCATimeIndex,-3]*Kscale[0],sol[i,j,PCATimeIndex,-2]*Kscale[1],2*sol[i,j,PCATimeIndex,-1]*Kscale[2]])\n",
    "Data_Var_Time_reshape = np.reshape(Data_Var_Time,(51*51,3))\n",
    "\n",
    "Time_Var_Vec = np.array([np.dot(Data_Var_Time,PCA_T_Vectors[PCATimeIndex,0]),np.dot(Data_Var_Time,PCA_T_Vectors[PCATimeIndex,1]),np.dot(Data_Var_Time,PCA_T_Vectors[PCATimeIndex,2])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate a percent error again for the first eigenvector between the \"true\" path and the grid of parameters\n",
    "\n",
    "Time_Error = np.divide(np.absolute(Time_Var_Vec[(0,) + truth_index] - Time_Var_Vec[0]),np.absolute(Time_Var_Vec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the error manifold - \"true\" path is again the white star and the 1% error curve is the white contour\n",
    "\n",
    "cont = plt.pcolormesh(kc,kb,Time_Error,norm = matplotlib.colors.LogNorm(),shading = 'gouraud',cmap = 'magma')\n",
    "plt.contour(kc,kb,Time_Error,levels = [0.1],colors = 'white')\n",
    "plt.scatter(kc[truth_index],kb[truth_index],marker = '*',color = 'white')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.colorbar(cont,label = 'Percent Error Compared to \"Truth\"')\n",
    "plt.ylabel('Cell Permeability')\n",
    "plt.xlabel('MicroCompartment Permeability')\n",
    "plt.title('Error Plot Using Most Variable Time Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do an error calculation for the full time series.\n",
    "\n",
    "In this case there is no manipulation of the product value, we're just using the \"raw\" output of the measurements to compare the curves\n",
    "\n",
    "One constraint is the selection of time points at which to do this analysis. Since the integration generated 1000 time points for each path (and this is extremely unrealistic for an experiment) I have subsampled down to 2 data points.\n",
    "In addition I have subsampled in such a way that the time points are chosen so that the \"true\" path (or data when we have real data) is well resolved. Meaning, the end point is about where the true path reaches equilibrium and we don't have a bunch of data sitting at steady state. This is done because collecting a lot of steady state data makes it harder to differentiate paths (since they all reach the same steady state) and because it is not realistic for us to continue running the experiment once the system has reached steady state.\n",
    "\n",
    "You can play around with the chosen times to see the effect of choosing different time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The error is calculated by setting the collected data to a T*3-dimensional vector (where T is the number of time points)\n",
    "#Then we take the difference between the \"true\" and estimated paths. The magnitude of this vector is calculated and scaled\n",
    "#by the magnitude of the vector for the \"true\" path. This gives a percent error between the two paths\n",
    "\n",
    "Series_Error = np.divide(np.sqrt(np.sum(np.square((sol[:,:,:80:4,-3:]-sol[truth_index][:80:4,-3:])*Kscale),axis = (2,3))),np.sqrt(np.sum(np.square((sol[truth_index][:80:4,-3:]*Kscale)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot heat map of entire series error - star is \"true\" - contour is 1% error\n",
    "\n",
    "cont = plt.pcolormesh(kc,kb,Series_Error,norm = matplotlib.colors.LogNorm(),shading = 'gouraud',cmap = 'magma')\n",
    "plt.contour(kc,kb,Series_Error,levels = [0.1],colors = 'white')\n",
    "plt.scatter(kc[truth_index],kb[truth_index],marker = '*',color = 'white')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.colorbar(cont,label = 'Percent Error Compared to \"Truth\"')\n",
    "plt.ylabel('Cell Permeability')\n",
    "plt.xlabel('MicroCompartment Permeability')\n",
    "plt.title('Error Plot Using Full Time Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all error maps together - All are plotted using the same colorbar and scale.\n",
    "#You can see that the most variable progress value constrains a smaller region than the most variable time point\n",
    "\n",
    "#You can also see that the \"good\" region chosen by the most variable progress value does just as well as the good region\n",
    "#using the whole time series. If different time points are chosen for the whole time series, the region may become more\n",
    "#poorly constrained than. The progress value calculation uses just one well chosen time point and contains the same\n",
    "#amount of information as the whole path\n",
    "\n",
    "plt.suptitle('Error Heat Map Using',fontsize = 20)\n",
    "\n",
    "plt.subplot(131)\n",
    "cont = plt.pcolormesh(kc,kb,PCA_Error,norm = matplotlib.colors.LogNorm(vmin=10**(-4.8), vmax=10**(2.3)),shading = 'gouraud',cmap = 'magma')\n",
    "plt.scatter(kc[truth_index],kb[truth_index],marker = '*',color = 'white')\n",
    "plt.contour(kc,kb,PCA_Error,levels = [0.1],colors = 'white')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Cell Permeability',fontsize = 18)\n",
    "plt.title('Most Variable\\nProgress Value',fontsize = 18)\n",
    "\n",
    "plt.subplot(132)\n",
    "cont = plt.pcolormesh(kc,kb,Time_Error,norm = matplotlib.colors.LogNorm(vmin=10**(-4.8), vmax=10**(2.3)),shading = 'gouraud',cmap = 'magma')\n",
    "plt.contour(kc,kb,Time_Error,levels = [0.1],colors = 'white')\n",
    "plt.scatter(kc[truth_index],kb[truth_index],marker = '*',color = 'white')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('MicroCompartment Permeability',fontsize = 18)\n",
    "plt.title('Most Variable\\nTime Value',fontsize = 18)\n",
    "\n",
    "plt.subplot(133)\n",
    "cont = plt.pcolormesh(kc,kb,Series_Error,norm = matplotlib.colors.LogNorm(vmin=10**(-4.8), vmax=10**(2.3)),shading = 'gouraud',cmap = 'magma')\n",
    "plt.contour(kc,kb,Series_Error,levels = [0.1],colors = 'white')\n",
    "plt.scatter(kc[truth_index],kb[truth_index],marker = '*',color = 'white')\n",
    "plt.colorbar(cont,label = 'Percent Error Compared to \"Truth\"')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title('Full Time Series\\n(Subsampled-20 time points)',fontsize = 18)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells attempt the integrate in terms of progress as an independent variable. This will lose all concept of time and the conversion back to time space will not be possible. On the above cells the integration is done in time. Based on a derivation for the \"progress\" variable, we can convert every x-t plot to an x-p plot (where x is a placeholder for a generic state in the system).\n",
    "\n",
    "To define progress we first set up our coordinates in the (2 * external Product,external Substrate) plane. We choose the factor of 2 in the x-coordinate because for this *specific* case, the product concentration is split into 2 products of equal concentration. We take into account that there is no loss of mass by doubling the final product. There should not be any difference in the final results if we don't use that factor of 2. We just need to  make sure to calculate all the terms (including slope and final states) correctly if this 2 is not included. Note that for a reversible reaction at time = 0 we start at $(0,S_0)$. And at time = equilibrium time we end at $(2 * P_f,0)$. If there is a ratio of $m_\\perp = \\frac{V_{ext}}{V_{ext}+V_{cell}}$ between the outside concentration and the total solution concentration, then we get $2\\cdot P_f = S_0 \\cdot m_\\perp$\n",
    "\n",
    "Then the line connecting the initial and final states of the system is the straight line from $(0,S_0) \\rightarrow (m_\\perp\\cdot S_0,0)$.\n",
    "\n",
    "We define the progress variable as a parametrization along this line that is equally distributed. The progress of a generic point $(2\\cdot P_{ext},S_{ext})$ is then given by projecting this curve onto the \"progress line\" in $(2\\cdot P_{ext},S_{ext})$ space and determining what fraction, $p$, of the way from the initial to final points this curve lies.\n",
    "\n",
    "Following some algebra, you get that the progress of a point can be calculated from its product and substrate values:\n",
    "\n",
    "\\begin{equation}p = \\frac{2 m_\\perp P_{ext} - S_{ext} + S_0}{S_0(1+m_\\perp^2)}\\end{equation}\n",
    "\n",
    "We can then calculate the change in progress over time:\n",
    "\n",
    "\\begin{equation}\\dot p = \\frac{1}{S_0(1+m_\\perp^2)} \\left[2 m_\\perp \\dot P_{ext} - \\dot S_{ext}\\right]\\end{equation}\n",
    "\n",
    "If we wish to covert our differential equations in time to equations in $p$ we can apply the chain rule. Define $\\mathbf{X}$ as the vector of state values and $\\dot{\\mathbf{X}} = \\mathbf{F}(\\mathbf{X})$. Then \n",
    "\n",
    "\\begin{gather}\n",
    "\\dot{\\mathbf{X}} = \\frac{d \\mathbf{X}}{d p} \\dot p\\\\\n",
    "\\frac{d \\mathbf{X}}{d p} = \\dot{\\mathbf{X}}\\cdot (\\dot p)^{-1}\\\\\n",
    "\\frac{d \\mathbf{X}}{d p} = \\mathbf{F}(\\mathbf{X}) \\cdot (\\dot p)^{-1}\\\\\n",
    "\\frac{d \\mathbf{X}}{d p} = \\frac{\\mathbf{F}(\\mathbf{X}) \\cdot(S_0(1+m_\\perp^2))}{2 m_\\perp \\dot P_{ext} - \\dot S_{ext}}\n",
    "\\end{gather} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
